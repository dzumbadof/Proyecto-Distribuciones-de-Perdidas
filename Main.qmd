---
title: Not used
subtitle: Not used
author:
  - name: Not used
editor: source
format:
  pdf:
    documentclass: scrbook
    classoption: ["onepage", "openany"]
    template-partials:
      - "before-body.tex"
      - "_titlepage.tex" 
    include-in-header: 
      - "in-header.tex"
    toc: true
    lof: true
    lot: true

bibliography: references.bib
---

```{r}
library(ggplot2)
library(tidyverse)
library(lubridate)
library(kableExtra)
library(dplyr)
```

# Bitácora 1

## Punto 1

## 1- Nombres de los integrantes

El grupo de trabajo estará integrado por:

-   Ignacio Barrantes Valerio, carné B50939

-   Leonardo Blanco Villalobos, carné B71139

-   David Zumbado Fernández, carné B88751

## 2- Idea

Se buscará modelar las pérdidas ligadas al extravío de equipajes en aeropuertos a partir de su frecuencia y severidad.

## 3- Reformulación de la idea de investigación

1.  ¿Cómo se puede modelar las pérdidas ligadas al extravío de equipajes en aeropuertos a partir de su frecuencia y severidad?

2.  ¿Cuáles distribuciones probabilísticas permiten modelar las pérdidas ligadas al extravío de equipajes en aeropuertos a partir de su frecuencia y severidad?

3.  ¿Por qué es importante modelar las pérdidas ligadas al extravío de equipajes en aeropuertos?

4.  ¿Cuáles métodos no paramétricos pueden emplearse en la modelación de las pérdidas ligadas al extravío o daños de equipajes en aeropuertos?



En la revisión de la literatura se ubican dos fuentes que emplean esta base de datos que la propuesta en la presente investigación y que persiguen el mismo objetivo, modelar la distribución de los costos de los reclamos, que son los trabajos de @flores y @chen2020aggregate. De esta manera, se comprueba que la fuente de la base de datos ha sido validada antes en investigaciones de corte académico y estrechamente relacionadas, además de estar adecuadamente referenciada y poder consultarse en @datoskelly2020data (ética). Se encontró que ambos trabajos utilizan métodos paramétricos; por esta razón, resulta de interés explorar también métodos no paramétricos alternativos que puedan llegar a usarse en el contexto de modelación de pérdidas en una aseguradora, por ejemplo (emocional). Un método no paramétrico que puede utilizarse es la estimación de densidades por medio de kernels (lógica). En @pitt2011estimation, se advierte que este método suele ser inadecuado en presencia de asimetría, por lo cual, si se llegase a comprobar dicha condición, una manera de proceder es aplicar una transformación previa a los datos, concretamente una perteneciente a la *shifted power transformation family* y aplicar la estimación por kernels a los datos transformados, obteniéndose la densidad estimada de los datos originales mediante un proceso de inversión explicado en el mismo artículo.

## Sección 5.

**Fuente de Información:**

Los datos se obtuvieron del Department of Homeland Security, un organismo del gobierno de Estados Unidos y se puede encontrar en @datos

```{r}
#Se cargan y depuran los datos
datos <- read.csv('tsa_claims.csv') %>% 
  clean_names() #se limpian nombres columnas
datos <- datos %>% mutate(date_received = dmy(date_received),
                      incident_date = mdy_hm(incident_date), 
                      claim_amount = as.numeric(gsub("\\$", "", claim_amount)),
                      close_amount = as.numeric(gsub("\\$", "", close_amount)))

```

**Contexto temporal y espacial de los datos:**

La base registra la ocurrencia de reclamos entre 2002 y 2015 en 466 aeropuertos alrededor de Estados Unidos.

**Facilidad de obtener la información:**

La base fue extraída de la página oficial del departamento de seguridad nacional la cual es accesible por cualquier persona por lo que se considera fácil de obtener.

**Población de estudio:**

Los aeropuertos

**Muestra observada:**

Aeropuertos estadounidenses donde se presentaron reclamos por daños ocasionados por seguridad.

**Unidad estadística o individuos:**

La unidad estadística es el registro de una ocurrencia de un reclamo.

**Descripción de las variables de la tabla:**

Los datos se conforman por 13 variables: claim_number es el identificador del reclamo, date_received es la fecha que se registró el reclamo, incident_date es la fecha que ocurrió el incidente que ameritó el reclamo, airport_code son las 3 letras que identifican el aeropuerto donde ocurrión el incidente, y airport_name es el nombre del aeropuerto. Claim_type es el tipo de daño ocasionado (daño a propiedad, daño a personas, entre otras), claim_site es el lugar dentro del aeropuerto donde sucedió el incidente. Item es el ítem que sufrió el daño, claim_amount es la cantidad en dólares que la persona pide, status es el estado del reclamo (se llegó a un acuerdo, se negó, etc... ), y close_amount fue el monto que efectivamente se pagó.

## Sección 8. Literatura

1.  **Título**: Modelling Dependencies in Airport Passenger Claim Data Using Copulas @flores **Autor:** Roberto Carcache Flores

    **Nombre del tema**: Modelación del riesgo utilizando cópulas

    **Forma de organizarlo**:

    -   Cronológico: Febrero 2022

    -   Metodológico: Cópulas bivariadas y multivariadas y simulaciones

    -   Temático: Funciones de distribución y dependencia de variables aleatorias

    -   Teoría: Probabilidad y estadística

    **Resumen en una oración**: Se encuentra la mejor distribución para la severidad y frecuencia de cada reclamo y luego estas distribuciones marginales se incorporan en diferentes modelos de cópulas

    **Argumento central**: En la metodología tradicional del modelamiento del riesgo se asume independencia entre frecuencia y severidad, lo cual no se hace en esta investigación. Además, se utiliza un proceso de eliminación de la tendencia con respecto al tiempo para mejorar los resultados.

    **Problemas con el argumento o el tema:** Las medidas de riesgo utilizando cópulas resultan en medidas de riesgo más altas que en los datos históricos.

    **Resumen en un párrafo**: Se eliminan los reclamos que fueron negados justificando el hecho de que el punto de la investigación es cuantificar los pagos que efectivamente fueron hechos, además del gran volumen de los datos. La agregación de los datos se hace por mes y con suma para la severidad y por frecuencia de los reclamos. El autor nota que hay un tendencia negativa de la frecuencia y severidad con respecto al tiempo por lo que procede a eliminar la tendencia. Luego determina la mejor marginal para cada variable utilizando MLE. Se encuentra que la binomial negativa se ajusta mejor a las frecuencias. Por otro lado la Log-Laplace se ajusta mejor a los reclamos por daños a la propiedad y la lognormal se ajusta mejor a los reclamos por pérdidas de los bienes por lo que se utilizan estas dos para modelar la severidad. Luego se procede a hacer algo similar con los resultados de eliminar la tendencia. Se encuentra que el proceso de eliminación de la tendencia facilita la búsqueda de una distribuciones. Se encuentra que todas las variables pares muestran algún tipo de dependencia en las colas. Finalmente, las cópulas multivariadas se comparan utilizando log verosimilitud y se obtiene que las cópulas elípticas (Gaussiana y t-Student) se ajustan mejor que las arquimedianas (Clayton y Gumbel).

2.  **Título**: Ignacio prueba

    **Autor:**

    **Nombre del tema**:

    **Forma de organizarlo**:

    -   Cronológico:

    -   Metodológico:

    -   Temático:

    -   Teoría: Probabilidad y estadística

    **Resumen en una oración**:

    **Argumento central**:

    **Problemas con el argumento o el tema:**

    **Resumen en un párrafo**:

3.  **Título**: *Estimation of Parametric and Nonparametric Models for Univariate Claim Severity Distributions - an approach using R* @pitt2011estimation
**Autores:** David Pitt, Montserrat Guillen y Catalina Bolancé

    **Nombre del tema**: Comparación de métodos paramétricos y no paramétricos apra modelar la severidad de reclamos en una aseguradora

    **Forma de organizarlo**:

    -   Cronológico: mayo de 2011

    -   Metodológico: estimación de densidades por Kernels modificados,

    -   Temático: Modelación de reclamos métidos y de seguros de automóviles

    -   Teoría: Probabilidad y estadística

    **Resumen en una oración**: Se encuentra que la estimación por kernels modificados es adecuada para modelar la distribución tanto de costos médicos como de reclamos en seguros de automóviles.

    **Argumento central**: Se pueden usar métodos no paramétricos para estimar distribuciones de reclamos en seguros de vehículo y de costos médicos.

    **Problemas con el argumento o el tema:** Los métodos clásicos de estimación de densidades por kernels suelen ser inadecaudos en presencia de asimetría, lo cual es común en datos de montos de reclamos en el contexto de seguros.

    **Resumen en un párrafo**: Se utilizan datos de costos de reclamos hechos a una aseguradora española por accidentes ocurridos en el año 2000 y recopilados en 2002, que incluye tanto los ligados a costos por daños a la propiedad como por costos médicos. El tamaño de muestra es de 518 reclamos. Para estimar la densidad para cada uno de los costos (daños a la propiedad y médicos) por separado, se utilizan métodos paramétricos y no paramétricos. Dentro de los paramétricos, se utilizaron aproximaciones normales y log-normales. Dentro de los no paramétricos, se utilizó una aproximación por kernels modificada, donde la modificación consiste en que primero se aplica una transformación a los datos originales para corregir la asimetría, se hace una aproximación con un kernel gaussiano a los datos modificados, y luego se calcula la aproximación de los datos originales a partir de la calculada para los modificados. La transformación aplicada a los datos se enmarca en la *shifted power transformation family*. Para evaluar la bondad de ajuste de todas las estimaciones propuestas, se utilizan distintas versiones log-verosimilitud tanto la versión clásica como modificaciones ponderadas, mientras que para evaluar solamente los métodos no paramétricos se usan distintas versiones de una aproximación a errores cuadráticos integrados ponderados. Se concluye que la log-verosimilitud no es una buena medida de bondad de ajuste para comparar los ajustes no paramétricos, debido a su relación inversa con la magnitud del ancho de banda empleado. En general, de las propuestas paramétricas, la log-normal tuvo un mejor desempeño mientras que la estimación por kernel modificada tuvo un desempeño adecuado y se recomienda para modelar distribuciones con colas pesadas.

# Referencias para escribir en Quarto

Según @knuth84 el comportamiento mono sí existe

# Metodología

```{r}
#| label: fig-monos
#| fig-cap: "City and highway mileage for 38 popular models of cars."
#| fig-alt: "Scatterplot of city vs. highway mileage for cars, where points are colored by the number of cylinders. The plot displays a positive, linear, and strong relationship between city and highway mileage, and mileage increases as the number cylinders decreases."
#| fig-width: 6
#| fig-height: 3.5


ggplot(mpg, aes(x = hwy, y = cty, color = cyl)) +
  geom_point(alpha = 0.5, size = 2) +
  scale_color_viridis_c() +
  theme_minimal()

```

La figura @fig-monos muestra un tendencia positiva en el comportamiento mono

# Referencias
